{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71d4241",
   "metadata": {},
   "source": [
    "# 로또 번호 예측 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6652049",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812590bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"lotto.csv\", index_col=0) # 순서 미포함\n",
    "df = pd.read_csv(\"lotto_ord.csv\", index_col=0) # 순서 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6238e1",
   "metadata": {},
   "source": [
    "최근 n개의 데이터만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f5fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df#[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4d7b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2   3   4   5   6   B\n",
       "1     37  23  10  33  29  40  16\n",
       "2     42  21   9  25  32  13   2\n",
       "3     31  21  27  19  11  16  30\n",
       "4     40  30  14  42  31  27   2\n",
       "5     16  42  29  40  24  41   3\n",
       "...   ..  ..  ..  ..  ..  ..  ..\n",
       "996    6  11  24  15  32  39  28\n",
       "997   16   7   4  44  24  14  20\n",
       "998   18  45  13  20  17  42  41\n",
       "999    9   1  28   3  18  14  34\n",
       "1000  19   2   8  22  42  32  39\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395c17e",
   "metadata": {},
   "source": [
    "당첨번호 리스트를 가공하여 sequences 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8ffa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 6000\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for _, seq in train.iterrows():\n",
    "    for i in range(1, len(seq)):\n",
    "        sequence = list(seq)[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d55428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 23, 10, 33, 29, 40, 16]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33a9cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 23],\n",
       " [37, 23, 10],\n",
       " [37, 23, 10, 33],\n",
       " [37, 23, 10, 33, 29],\n",
       " [37, 23, 10, 33, 29, 40]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e01483",
   "metadata": {},
   "source": [
    "잘린 sequences의 길이를 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=7, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd9c3407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (6000, 6)\n",
      "y.shape: (6000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa58aa",
   "metadata": {},
   "source": [
    "padding후 0으로 채워진다. (0~45 총 46의 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cefd164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0, 37, 23],\n",
       "       [ 0,  0,  0,  0, 37, 23, 10],\n",
       "       [ 0,  0,  0, 37, 23, 10, 33],\n",
       "       [ 0,  0, 37, 23, 10, 33, 29],\n",
       "       [ 0, 37, 23, 10, 33, 29, 40]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab662d",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134bb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(45+1, 10))\n",
    "model.add(LSTM(64, input_shape=(6, 1), return_sequences=False))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(45+1, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43efeae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seungwon\\anaconda3\\envs\\scratch\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5075: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "94/94 [==============================] - 3s 5ms/step - loss: 3.8241 - acc: 0.0207\n",
      "Epoch 2/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.8121 - acc: 0.0208\n",
      "Epoch 3/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.8086 - acc: 0.0255\n",
      "Epoch 4/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.8070 - acc: 0.0238\n",
      "Epoch 5/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.8047 - acc: 0.0247\n",
      "Epoch 6/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.8008 - acc: 0.0263\n",
      "Epoch 7/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7949 - acc: 0.0277\n",
      "Epoch 8/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7864 - acc: 0.0298\n",
      "Epoch 9/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7756 - acc: 0.0363\n",
      "Epoch 10/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7644 - acc: 0.0380\n",
      "Epoch 11/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7520 - acc: 0.0405\n",
      "Epoch 12/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7424 - acc: 0.0420\n",
      "Epoch 13/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7299 - acc: 0.0427\n",
      "Epoch 14/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7176 - acc: 0.0495\n",
      "Epoch 15/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.7068 - acc: 0.0467\n",
      "Epoch 16/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6928 - acc: 0.0503\n",
      "Epoch 17/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6779 - acc: 0.0502\n",
      "Epoch 18/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6661 - acc: 0.0522\n",
      "Epoch 19/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6481 - acc: 0.0590\n",
      "Epoch 20/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6334 - acc: 0.0640\n",
      "Epoch 21/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6194 - acc: 0.0622\n",
      "Epoch 22/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.6006 - acc: 0.0663\n",
      "Epoch 23/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.5878 - acc: 0.0675\n",
      "Epoch 24/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.5693 - acc: 0.0720\n",
      "Epoch 25/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.5502 - acc: 0.0788\n",
      "Epoch 26/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.5315 - acc: 0.0815\n",
      "Epoch 27/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.5135 - acc: 0.0838\n",
      "Epoch 28/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.4930 - acc: 0.0887\n",
      "Epoch 29/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.4725 - acc: 0.0940\n",
      "Epoch 30/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.4555 - acc: 0.0978\n",
      "Epoch 31/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.4338 - acc: 0.1012\n",
      "Epoch 32/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.4124 - acc: 0.1102\n",
      "Epoch 33/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.3897 - acc: 0.1135\n",
      "Epoch 34/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 3.3694 - acc: 0.1225\n",
      "Epoch 35/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 3.3443 - acc: 0.1225\n",
      "Epoch 36/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.3276 - acc: 0.1268\n",
      "Epoch 37/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.3067 - acc: 0.1340\n",
      "Epoch 38/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.2793 - acc: 0.1452\n",
      "Epoch 39/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.2545 - acc: 0.1443\n",
      "Epoch 40/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.2324 - acc: 0.1513\n",
      "Epoch 41/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.2117 - acc: 0.1572\n",
      "Epoch 42/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.1877 - acc: 0.1635\n",
      "Epoch 43/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.1617 - acc: 0.1743\n",
      "Epoch 44/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.1425 - acc: 0.1742\n",
      "Epoch 45/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.1142 - acc: 0.1855\n",
      "Epoch 46/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.0905 - acc: 0.1883\n",
      "Epoch 47/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.0696 - acc: 0.1923\n",
      "Epoch 48/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.0404 - acc: 0.1995\n",
      "Epoch 49/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 3.0164 - acc: 0.2077\n",
      "Epoch 50/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.9919 - acc: 0.2105\n",
      "Epoch 51/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.9657 - acc: 0.2182\n",
      "Epoch 52/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.9428 - acc: 0.2253\n",
      "Epoch 53/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.9171 - acc: 0.2358\n",
      "Epoch 54/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.8899 - acc: 0.2422\n",
      "Epoch 55/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.8676 - acc: 0.2442\n",
      "Epoch 56/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.8416 - acc: 0.2507\n",
      "Epoch 57/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.8160 - acc: 0.2632\n",
      "Epoch 58/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.7925 - acc: 0.2677\n",
      "Epoch 59/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.7636 - acc: 0.2733\n",
      "Epoch 60/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 2.7460 - acc: 0.2820\n",
      "Epoch 61/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.7179 - acc: 0.2870\n",
      "Epoch 62/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.6906 - acc: 0.2947\n",
      "Epoch 63/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.6679 - acc: 0.3047\n",
      "Epoch 64/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.6467 - acc: 0.3122\n",
      "Epoch 65/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.6218 - acc: 0.3133\n",
      "Epoch 66/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5988 - acc: 0.3223\n",
      "Epoch 67/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5715 - acc: 0.3295\n",
      "Epoch 68/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5468 - acc: 0.3367\n",
      "Epoch 69/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5283 - acc: 0.3453\n",
      "Epoch 70/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.5039 - acc: 0.3533\n",
      "Epoch 71/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4836 - acc: 0.3540\n",
      "Epoch 72/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4585 - acc: 0.3647\n",
      "Epoch 73/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4366 - acc: 0.3715\n",
      "Epoch 74/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.4120 - acc: 0.3780\n",
      "Epoch 75/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3929 - acc: 0.3847\n",
      "Epoch 76/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3712 - acc: 0.3867\n",
      "Epoch 77/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3468 - acc: 0.3995\n",
      "Epoch 78/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3270 - acc: 0.3983\n",
      "Epoch 79/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.3144 - acc: 0.4073\n",
      "Epoch 80/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2863 - acc: 0.4167\n",
      "Epoch 81/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2682 - acc: 0.4173\n",
      "Epoch 82/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2450 - acc: 0.4305\n",
      "Epoch 83/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2276 - acc: 0.4337\n",
      "Epoch 84/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.2003 - acc: 0.4385\n",
      "Epoch 85/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1832 - acc: 0.4405\n",
      "Epoch 86/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1641 - acc: 0.4470\n",
      "Epoch 87/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1434 - acc: 0.4555\n",
      "Epoch 88/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1252 - acc: 0.4585\n",
      "Epoch 89/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.1051 - acc: 0.4635\n",
      "Epoch 90/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.0859 - acc: 0.4692\n",
      "Epoch 91/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.0704 - acc: 0.4730\n",
      "Epoch 92/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.0493 - acc: 0.4773\n",
      "Epoch 93/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.0308 - acc: 0.4850\n",
      "Epoch 94/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 2.0098 - acc: 0.4875\n",
      "Epoch 95/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9996 - acc: 0.4917\n",
      "Epoch 96/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9762 - acc: 0.5012\n",
      "Epoch 97/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9613 - acc: 0.5035\n",
      "Epoch 98/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9441 - acc: 0.5143\n",
      "Epoch 99/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9260 - acc: 0.5120\n",
      "Epoch 100/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.9026 - acc: 0.5205\n",
      "Epoch 101/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8884 - acc: 0.5285\n",
      "Epoch 102/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8723 - acc: 0.5308\n",
      "Epoch 103/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8522 - acc: 0.5422\n",
      "Epoch 104/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8376 - acc: 0.5402\n",
      "Epoch 105/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8250 - acc: 0.5402\n",
      "Epoch 106/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.8124 - acc: 0.5495\n",
      "Epoch 107/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7973 - acc: 0.5480\n",
      "Epoch 108/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7735 - acc: 0.5573\n",
      "Epoch 109/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7578 - acc: 0.5600\n",
      "Epoch 110/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7433 - acc: 0.5653\n",
      "Epoch 111/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7275 - acc: 0.5722\n",
      "Epoch 112/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.7098 - acc: 0.5775\n",
      "Epoch 113/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6989 - acc: 0.5782\n",
      "Epoch 114/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6825 - acc: 0.5802\n",
      "Epoch 115/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6712 - acc: 0.5853\n",
      "Epoch 116/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6544 - acc: 0.5922\n",
      "Epoch 117/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6409 - acc: 0.5943\n",
      "Epoch 118/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6283 - acc: 0.5978\n",
      "Epoch 119/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.6147 - acc: 0.6027\n",
      "Epoch 120/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5983 - acc: 0.6060\n",
      "Epoch 121/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5831 - acc: 0.6098\n",
      "Epoch 122/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5705 - acc: 0.6133\n",
      "Epoch 123/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5590 - acc: 0.6135\n",
      "Epoch 124/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5459 - acc: 0.6175\n",
      "Epoch 125/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5297 - acc: 0.6222\n",
      "Epoch 126/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5181 - acc: 0.6260\n",
      "Epoch 127/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.5084 - acc: 0.6268\n",
      "Epoch 128/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4930 - acc: 0.6312\n",
      "Epoch 129/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4857 - acc: 0.6315\n",
      "Epoch 130/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4688 - acc: 0.6420\n",
      "Epoch 131/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4626 - acc: 0.6422\n",
      "Epoch 132/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4417 - acc: 0.6393\n",
      "Epoch 133/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4267 - acc: 0.6525\n",
      "Epoch 134/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4214 - acc: 0.6487\n",
      "Epoch 135/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4060 - acc: 0.6558\n",
      "Epoch 136/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.4004 - acc: 0.6563\n",
      "Epoch 137/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3856 - acc: 0.6593\n",
      "Epoch 138/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3796 - acc: 0.6610\n",
      "Epoch 139/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3680 - acc: 0.6688\n",
      "Epoch 140/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3516 - acc: 0.6667\n",
      "Epoch 141/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3453 - acc: 0.6690\n",
      "Epoch 142/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3323 - acc: 0.6742\n",
      "Epoch 143/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3218 - acc: 0.6723\n",
      "Epoch 144/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3137 - acc: 0.6795\n",
      "Epoch 145/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.3030 - acc: 0.6825\n",
      "Epoch 146/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2899 - acc: 0.6847\n",
      "Epoch 147/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2761 - acc: 0.6852\n",
      "Epoch 148/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2725 - acc: 0.6862\n",
      "Epoch 149/200\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 1.2650 - acc: 0.6872\n",
      "Epoch 150/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2541 - acc: 0.6892\n",
      "Epoch 151/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2438 - acc: 0.6962\n",
      "Epoch 152/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2403 - acc: 0.6937\n",
      "Epoch 153/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 1.2289 - acc: 0.6960\n",
      "Epoch 154/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 1.2173 - acc: 0.6988\n",
      "Epoch 155/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 1.2137 - acc: 0.7010\n",
      "Epoch 156/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.2031 - acc: 0.7053\n",
      "Epoch 157/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1915 - acc: 0.7065\n",
      "Epoch 158/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1817 - acc: 0.7068\n",
      "Epoch 159/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1703 - acc: 0.7100\n",
      "Epoch 160/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 1.1626 - acc: 0.7122\n",
      "Epoch 161/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1629 - acc: 0.7140\n",
      "Epoch 162/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1481 - acc: 0.7125\n",
      "Epoch 163/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1421 - acc: 0.7168\n",
      "Epoch 164/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1324 - acc: 0.7187\n",
      "Epoch 165/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1201 - acc: 0.7205\n",
      "Epoch 166/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1160 - acc: 0.7250\n",
      "Epoch 167/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1076 - acc: 0.7198\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 5ms/step - loss: 1.1052 - acc: 0.7207\n",
      "Epoch 169/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0978 - acc: 0.7238\n",
      "Epoch 170/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0891 - acc: 0.7252\n",
      "Epoch 171/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0842 - acc: 0.7273\n",
      "Epoch 172/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0737 - acc: 0.7293\n",
      "Epoch 173/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0680 - acc: 0.7297\n",
      "Epoch 174/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0625 - acc: 0.7295\n",
      "Epoch 175/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0531 - acc: 0.7343\n",
      "Epoch 176/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0492 - acc: 0.7335\n",
      "Epoch 177/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0422 - acc: 0.7362\n",
      "Epoch 178/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0330 - acc: 0.7378\n",
      "Epoch 179/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0333 - acc: 0.7330\n",
      "Epoch 180/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0204 - acc: 0.7433\n",
      "Epoch 181/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0113 - acc: 0.7410\n",
      "Epoch 182/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0069 - acc: 0.7412\n",
      "Epoch 183/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 1.0037 - acc: 0.7442\n",
      "Epoch 184/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9946 - acc: 0.7440\n",
      "Epoch 185/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9907 - acc: 0.7458\n",
      "Epoch 186/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9818 - acc: 0.7470\n",
      "Epoch 187/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9763 - acc: 0.7505\n",
      "Epoch 188/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9749 - acc: 0.7515\n",
      "Epoch 189/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9707 - acc: 0.7482\n",
      "Epoch 190/200\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.9788 - acc: 0.7467\n",
      "Epoch 191/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9625 - acc: 0.7525\n",
      "Epoch 192/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9526 - acc: 0.7548\n",
      "Epoch 193/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9531 - acc: 0.7548\n",
      "Epoch 194/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9432 - acc: 0.7552\n",
      "Epoch 195/200\n",
      "94/94 [==============================] - 1s 6ms/step - loss: 0.9352 - acc: 0.7558\n",
      "Epoch 196/200\n",
      "94/94 [==============================] - 1s 5ms/step - loss: 0.9302 - acc: 0.7560\n",
      "Epoch 197/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9262 - acc: 0.7582\n",
      "Epoch 198/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9237 - acc: 0.7560\n",
      "Epoch 199/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9212 - acc: 0.7612\n",
      "Epoch 200/200\n",
      "94/94 [==============================] - 0s 5ms/step - loss: 0.9142 - acc: 0.7617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b88b5a6c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a580bdf",
   "metadata": {},
   "source": [
    "### 번호 리스트를 반환하는  함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514f6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def seq_generate(model, input_num, verbose=False): \n",
    "    sequence = [input_num]\n",
    "\n",
    "    while len(sequence) < 7:\n",
    "        encoded = pad_sequences([sequence], maxlen=7, padding='pre')\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        \n",
    "        mask = np.zeros(result.size, dtype=bool)\n",
    "        mask[sequence] = True\n",
    "        result = np.ma.array(result, mask=mask)\n",
    "        result = np.argmax(result)\n",
    "\n",
    "        sequence.append(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"sequence:\", sequence)\n",
    "\n",
    "    return sorted(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36adcc8",
   "metadata": {},
   "source": [
    "테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6854132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.26557035e-15 1.08643947e-02 1.00932139e-05 1.43000980e-05\n",
      "  8.05335306e-03 5.33186411e-03 1.40156541e-02 1.02390014e-02\n",
      "  4.81116399e-02 5.50538711e-02 3.80362011e-03 4.24289657e-03\n",
      "  2.92597506e-02 9.20619641e-04 1.18962368e-02 5.01444098e-03\n",
      "  1.92005280e-02 1.53621912e-01 1.38556375e-03 1.33279755e-04\n",
      "  3.95237934e-04 4.06804914e-03 7.42011219e-02 2.90906732e-03\n",
      "  2.42458005e-02 1.97518058e-03 2.44950003e-04 9.51450411e-03\n",
      "  5.64707071e-02 3.59455086e-02 1.22266589e-02 1.36154677e-05\n",
      "  1.39822394e-01 2.16146559e-02 1.36946574e-05 6.64970726e-02\n",
      "  1.53096637e-03 3.20121821e-04 1.09302765e-02 8.81507352e-04\n",
      "  6.83743638e-05 1.88312342e-03 2.55329511e-03 3.22266744e-04\n",
      "  1.49313003e-01 8.65859212e-04]]\n",
      "17\n",
      "sequence: [2, 17]\n",
      "sequence: [2, 17, 24]\n",
      "sequence: [2, 17, 24, 19]\n",
      "sequence: [2, 17, 24, 19, 45]\n",
      "sequence: [2, 17, 24, 19, 45, 3]\n",
      "sequence: [2, 17, 24, 19, 45, 3, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 17, 19, 24, 25, 45]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = 2\n",
    "seq = [[test_num]]\n",
    "encoded = pad_sequences(seq, maxlen=7, padding='pre')\n",
    "result = model.predict(encoded, verbose=0)\n",
    "\n",
    "print(result)\n",
    "print(np.argmax(result))\n",
    "\n",
    "seq_generate(model, test_num, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92949b2",
   "metadata": {},
   "source": [
    "### 수행 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762b6c6",
   "metadata": {},
   "source": [
    "첫번째로 나오는 번호 빈도순으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41adce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    35\n",
       "25    31\n",
       "26    31\n",
       "23    29\n",
       "4     28\n",
       "45    28\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_num = df['1'].value_counts()[:6]\n",
    "first_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cd235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37: [4, 17, 25, 33, 37, 41, 43]\n",
      "25: [2, 4, 7, 22, 24, 25, 43]\n",
      "26: [1, 9, 26, 28, 34, 41, 42]\n",
      "23: [5, 10, 14, 20, 23, 27, 42]\n",
      " 4: [3, 4, 5, 8, 11, 27, 37]\n",
      "45: [3, 7, 22, 36, 40, 42, 45]\n"
     ]
    }
   ],
   "source": [
    "for num, _ in first_num.iteritems():\n",
    "    print(f\"{num:2}:\", seq_generate(model, num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3e583",
   "metadata": {},
   "source": [
    "모든 숫자에 대해 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f395e8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: [1, 12, 16, 32, 41, 42, 45]\n",
      " 2: [2, 3, 17, 19, 24, 25, 45]\n",
      " 3: [3, 5, 12, 13, 26, 30, 42]\n",
      " 4: [3, 4, 5, 8, 11, 27, 37]\n",
      " 5: [5, 10, 14, 18, 26, 39, 43]\n",
      " 6: [6, 12, 13, 18, 27, 31, 43]\n",
      " 7: [1, 7, 8, 31, 36, 37, 43]\n",
      " 8: [8, 12, 13, 14, 18, 21, 28]\n",
      " 9: [7, 9, 11, 16, 31, 38, 39]\n",
      "10: [4, 6, 10, 15, 27, 41, 42]\n",
      "11: [5, 8, 11, 15, 21, 40, 42]\n",
      "12: [10, 12, 14, 18, 24, 27, 45]\n",
      "13: [1, 7, 8, 13, 25, 36, 44]\n",
      "14: [3, 4, 14, 20, 28, 42, 44]\n",
      "15: [4, 12, 14, 15, 17, 23, 28]\n",
      "16: [12, 16, 17, 23, 25, 40, 45]\n",
      "17: [5, 12, 17, 27, 32, 37, 38]\n",
      "18: [4, 12, 18, 26, 27, 29, 33]\n",
      "19: [4, 7, 13, 19, 25, 34, 45]\n",
      "20: [5, 7, 17, 19, 20, 24, 27]\n",
      "21: [1, 6, 14, 18, 21, 29, 34]\n",
      "22: [10, 20, 22, 33, 40, 41, 45]\n",
      "23: [5, 10, 14, 20, 23, 27, 42]\n",
      "24: [3, 24, 26, 27, 29, 37, 45]\n",
      "25: [2, 4, 7, 22, 24, 25, 43]\n",
      "26: [1, 9, 26, 28, 34, 41, 42]\n",
      "27: [9, 14, 25, 27, 28, 33, 37]\n",
      "28: [3, 19, 23, 28, 34, 38, 42]\n",
      "29: [1, 2, 7, 9, 19, 29, 42]\n",
      "30: [1, 3, 7, 14, 18, 26, 30]\n",
      "31: [8, 13, 14, 18, 31, 39, 40]\n",
      "32: [3, 4, 11, 17, 27, 32, 45]\n",
      "33: [7, 11, 18, 27, 28, 33, 43]\n",
      "34: [4, 6, 25, 27, 34, 37, 40]\n",
      "35: [3, 15, 28, 35, 37, 42, 43]\n",
      "36: [17, 27, 33, 36, 37, 40, 45]\n",
      "37: [4, 17, 25, 33, 37, 41, 43]\n",
      "38: [7, 12, 27, 31, 34, 38, 42]\n",
      "39: [13, 27, 28, 37, 39, 40, 41]\n",
      "40: [1, 10, 17, 27, 28, 29, 40]\n",
      "41: [4, 12, 13, 18, 29, 39, 41]\n",
      "42: [4, 7, 8, 26, 27, 36, 42]\n",
      "43: [2, 11, 18, 19, 30, 41, 43]\n",
      "44: [7, 12, 29, 31, 38, 40, 44]\n",
      "45: [3, 7, 22, 36, 40, 42, 45]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 46):\n",
    "    print(f\"{i:2}:\", seq_generate(model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069ba97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
