{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71d4241",
   "metadata": {},
   "source": [
    "# California lotto number prediction project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6652049",
   "metadata": {},
   "source": [
    "### data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812590bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
   "# df = pd.read_csv(\"lotto.csv\", index_col=0) # No order\n",
    "df = pd.read_csv(\"lotto_ord.csv\", index_col=0) # with order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6d42e",
   "metadata": {},
   "source": [
    "Use only the most recent n data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f5fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df#[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9424f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2   3   4   5   6   B\n",
       "1     37  23  10  33  29  40  16\n",
       "2     42  21   9  25  32  13   2\n",
       "3     31  21  27  19  11  16  30\n",
       "4     40  30  14  42  31  27   2\n",
       "5     16  42  29  40  24  41   3\n",
       "...   ..  ..  ..  ..  ..  ..  ..\n",
       "997   16   7   4  44  24  14  20\n",
       "998   18  45  13  20  17  42  41\n",
       "999    9   1  28   3  18  14  34\n",
       "1000  19   2   8  22  42  32  39\n",
       "1000  12  14  10  20   6  42  15\n",
       "\n",
       "[1001 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395c17e",
   "metadata": {},
   "source": [
    "Process the winning number list to create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8ffa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     "Number of samples to use for training: 6006\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "for _, seq in train.iterrows():\n",
    "    for i in range(1, len(seq)):\n",
    "        sequence = list(seq)[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
   "print('Number of samples to use for training: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f46421f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 23, 10, 33, 29, 40, 16]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45432608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 23],\n",
       " [37, 23, 10],\n",
       " [37, 23, 10, 33],\n",
       " [37, 23, 10, 33, 29],\n",
       " [37, 23, 10, 33, 29, 40]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a79d",
   "metadata": {},
   "source": [
    "잘린 sequences의 길이를 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=7, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e156cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (6006, 6)\n",
      "y.shape: (6006,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838da18d",
   "metadata": {},
   "source": [
"It is padded with zeros after padding. (0-45 total size of 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40e02b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0, 37, 23],\n",
       "       [ 0,  0,  0,  0, 37, 23, 10],\n",
       "       [ 0,  0,  0, 37, 23, 10, 33],\n",
       "       [ 0,  0, 37, 23, 10, 33, 29],\n",
       "       [ 0, 37, 23, 10, 33, 29, 40]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490dfebf",
   "metadata": {},
   "source": [
  "Separate Test/Verification Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492eaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ba5164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  6, 12],\n",
       "       [ 0,  0,  0,  0, 35,  5],\n",
       "       [ 0,  0, 11, 23, 40, 17]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab662d",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134bb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(45+1, 10))\n",
    "model.add(LSTM(64, input_shape=(6, 1), return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(45+1, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd737eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(45+1, 10))\n",
    "model.add(Bidirectional(LSTM(64, input_shape=(6, 1), return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(45+1, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c61fe59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seungwon\\anaconda3\\envs\\scratch\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5075: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 7s 28ms/step - loss: 3.8247 - acc: 0.0221 - val_loss: 3.8207 - val_acc: 0.0237\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.8139 - acc: 0.0244 - val_loss: 3.8174 - val_acc: 0.0197\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.8101 - acc: 0.0261 - val_loss: 3.8146 - val_acc: 0.0227\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.8061 - acc: 0.0244 - val_loss: 3.8155 - val_acc: 0.0192\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.8034 - acc: 0.0301 - val_loss: 3.8148 - val_acc: 0.0192\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7993 - acc: 0.0253 - val_loss: 3.8168 - val_acc: 0.0187\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7946 - acc: 0.0323 - val_loss: 3.8177 - val_acc: 0.0197\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7901 - acc: 0.0333 - val_loss: 3.8195 - val_acc: 0.0217\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 3.7822 - acc: 0.0355 - val_loss: 3.8282 - val_acc: 0.0177\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.7718 - acc: 0.0413 - val_loss: 3.8421 - val_acc: 0.0202\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7628 - acc: 0.0410 - val_loss: 3.8454 - val_acc: 0.0227\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7543 - acc: 0.0445 - val_loss: 3.8381 - val_acc: 0.0202\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7445 - acc: 0.0403 - val_loss: 3.8486 - val_acc: 0.0192\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7306 - acc: 0.0435 - val_loss: 3.8621 - val_acc: 0.0166\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7163 - acc: 0.0465 - val_loss: 3.8748 - val_acc: 0.0227\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.7058 - acc: 0.0534 - val_loss: 3.8876 - val_acc: 0.0172\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.6861 - acc: 0.0490 - val_loss: 3.9126 - val_acc: 0.0197\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.6727 - acc: 0.0529 - val_loss: 3.9160 - val_acc: 0.0166\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.6465 - acc: 0.0579 - val_loss: 3.9280 - val_acc: 0.0166\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.6217 - acc: 0.0579 - val_loss: 3.9518 - val_acc: 0.0156\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.5998 - acc: 0.0664 - val_loss: 3.9414 - val_acc: 0.0187\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.5700 - acc: 0.0708 - val_loss: 4.0046 - val_acc: 0.0182\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 3.5338 - acc: 0.0805 - val_loss: 4.0233 - val_acc: 0.0227\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.5021 - acc: 0.0860 - val_loss: 4.0725 - val_acc: 0.0227\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 3.4508 - acc: 0.1024 - val_loss: 4.1072 - val_acc: 0.0187\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 3.4091 - acc: 0.1036 - val_loss: 4.1261 - val_acc: 0.0247\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.3568 - acc: 0.1170 - val_loss: 4.1839 - val_acc: 0.0207\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.2998 - acc: 0.1359 - val_loss: 4.2522 - val_acc: 0.0252\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.2474 - acc: 0.1424 - val_loss: 4.2405 - val_acc: 0.0237\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.1804 - acc: 0.1548 - val_loss: 4.3395 - val_acc: 0.0252\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.1212 - acc: 0.1680 - val_loss: 4.3646 - val_acc: 0.0232\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.0499 - acc: 0.1931 - val_loss: 4.4036 - val_acc: 0.0257\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 3.0003 - acc: 0.2040 - val_loss: 4.4647 - val_acc: 0.0257\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.9243 - acc: 0.2261 - val_loss: 4.5365 - val_acc: 0.0277\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.8569 - acc: 0.2416 - val_loss: 4.5652 - val_acc: 0.0232\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.7860 - acc: 0.2550 - val_loss: 4.6215 - val_acc: 0.0283\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.7246 - acc: 0.2818 - val_loss: 4.6648 - val_acc: 0.0242\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.6534 - acc: 0.2970 - val_loss: 4.7361 - val_acc: 0.0283\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.5785 - acc: 0.3248 - val_loss: 4.7757 - val_acc: 0.0313\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.5068 - acc: 0.3382 - val_loss: 4.9011 - val_acc: 0.0237\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.4397 - acc: 0.3638 - val_loss: 4.9643 - val_acc: 0.0247\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.3633 - acc: 0.3839 - val_loss: 5.0975 - val_acc: 0.0288\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.3014 - acc: 0.4021 - val_loss: 5.1002 - val_acc: 0.0298\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.2304 - acc: 0.4155 - val_loss: 5.1720 - val_acc: 0.0298\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.1606 - acc: 0.4351 - val_loss: 5.2785 - val_acc: 0.0252\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.1005 - acc: 0.4548 - val_loss: 5.3137 - val_acc: 0.0247\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 2.0462 - acc: 0.4761 - val_loss: 5.4251 - val_acc: 0.0293\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.9735 - acc: 0.4938 - val_loss: 5.5243 - val_acc: 0.0277\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9097 - acc: 0.5122 - val_loss: 5.6109 - val_acc: 0.0257\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8548 - acc: 0.5313 - val_loss: 5.6940 - val_acc: 0.0293\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7968 - acc: 0.5440 - val_loss: 5.7384 - val_acc: 0.0267\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7576 - acc: 0.5586 - val_loss: 5.7870 - val_acc: 0.0242\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6830 - acc: 0.5803 - val_loss: 5.8937 - val_acc: 0.0252\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6333 - acc: 0.5870 - val_loss: 6.0203 - val_acc: 0.0222\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5812 - acc: 0.6079 - val_loss: 6.1262 - val_acc: 0.0232\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.5503 - acc: 0.6096 - val_loss: 6.1005 - val_acc: 0.0267\n",
      "Epoch 57/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.4963 - acc: 0.6270 - val_loss: 6.2592 - val_acc: 0.0232\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.4466 - acc: 0.6362 - val_loss: 6.2953 - val_acc: 0.0242\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.4037 - acc: 0.6523 - val_loss: 6.3921 - val_acc: 0.0197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.3535 - acc: 0.6658 - val_loss: 6.4698 - val_acc: 0.0192\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.3133 - acc: 0.6732 - val_loss: 6.5736 - val_acc: 0.0232\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.2783 - acc: 0.6834 - val_loss: 6.7413 - val_acc: 0.0222\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.2415 - acc: 0.6891 - val_loss: 6.7613 - val_acc: 0.0222\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.2138 - acc: 0.6991 - val_loss: 6.8348 - val_acc: 0.0277\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.1875 - acc: 0.7015 - val_loss: 6.9396 - val_acc: 0.0187\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.1522 - acc: 0.7172 - val_loss: 7.0669 - val_acc: 0.0207\n",
      "Epoch 67/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.1252 - acc: 0.7167 - val_loss: 7.0656 - val_acc: 0.0197\n",
      "Epoch 68/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.0830 - acc: 0.7304 - val_loss: 7.1741 - val_acc: 0.0257\n",
      "Epoch 69/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.0591 - acc: 0.7291 - val_loss: 7.2586 - val_acc: 0.0232\n",
      "Epoch 70/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.0370 - acc: 0.7378 - val_loss: 7.2977 - val_acc: 0.0207\n",
      "Epoch 71/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.0116 - acc: 0.7435 - val_loss: 7.4129 - val_acc: 0.0217\n",
      "Epoch 72/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.9708 - acc: 0.7570 - val_loss: 7.5183 - val_acc: 0.0222\n",
      "Epoch 73/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.9475 - acc: 0.7594 - val_loss: 7.6347 - val_acc: 0.0232\n",
      "Epoch 74/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.9219 - acc: 0.7674 - val_loss: 7.7005 - val_acc: 0.0247\n",
      "Epoch 75/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.9103 - acc: 0.7659 - val_loss: 7.7329 - val_acc: 0.0227\n",
      "Epoch 76/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.8961 - acc: 0.7758 - val_loss: 7.7896 - val_acc: 0.0222\n",
      "Epoch 77/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8628 - acc: 0.7793 - val_loss: 7.9240 - val_acc: 0.0207\n",
      "Epoch 78/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8639 - acc: 0.7734 - val_loss: 7.9823 - val_acc: 0.0217\n",
      "Epoch 79/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8440 - acc: 0.7823 - val_loss: 8.0929 - val_acc: 0.0237\n",
      "Epoch 80/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.8201 - acc: 0.7848 - val_loss: 8.1198 - val_acc: 0.0237\n",
      "Epoch 81/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8172 - acc: 0.7833 - val_loss: 8.2004 - val_acc: 0.0217\n",
      "Epoch 82/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8041 - acc: 0.7863 - val_loss: 8.2900 - val_acc: 0.0227\n",
      "Epoch 83/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.8015 - acc: 0.7858 - val_loss: 8.3319 - val_acc: 0.0207\n",
      "Epoch 84/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7876 - acc: 0.7905 - val_loss: 8.4271 - val_acc: 0.0237\n",
      "Epoch 85/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7714 - acc: 0.7920 - val_loss: 8.4468 - val_acc: 0.0247\n",
      "Epoch 86/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7644 - acc: 0.7908 - val_loss: 8.4950 - val_acc: 0.0227\n",
      "Epoch 87/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7588 - acc: 0.7927 - val_loss: 8.5189 - val_acc: 0.0217\n",
      "Epoch 88/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7527 - acc: 0.7898 - val_loss: 8.5145 - val_acc: 0.0237\n",
      "Epoch 89/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7460 - acc: 0.7962 - val_loss: 8.7683 - val_acc: 0.0222\n",
      "Epoch 90/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7225 - acc: 0.7990 - val_loss: 8.7774 - val_acc: 0.0207\n",
      "Epoch 91/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7304 - acc: 0.7937 - val_loss: 8.8499 - val_acc: 0.0247\n",
      "Epoch 92/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7183 - acc: 0.7935 - val_loss: 8.9341 - val_acc: 0.0252\n",
      "Epoch 93/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7221 - acc: 0.7957 - val_loss: 8.9481 - val_acc: 0.0222\n",
      "Epoch 94/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7308 - acc: 0.7935 - val_loss: 8.9251 - val_acc: 0.0202\n",
      "Epoch 95/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.7256 - acc: 0.7890 - val_loss: 9.0165 - val_acc: 0.0257\n",
      "Epoch 96/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.7145 - acc: 0.7950 - val_loss: 9.1246 - val_acc: 0.0257\n",
      "Epoch 97/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6868 - acc: 0.7985 - val_loss: 9.1440 - val_acc: 0.0252\n",
      "Epoch 98/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6769 - acc: 0.7985 - val_loss: 9.1761 - val_acc: 0.0283\n",
      "Epoch 99/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6823 - acc: 0.8022 - val_loss: 9.2287 - val_acc: 0.0237\n",
      "Epoch 100/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6791 - acc: 0.8034 - val_loss: 9.2464 - val_acc: 0.0247\n",
      "Epoch 101/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6627 - acc: 0.7997 - val_loss: 9.2297 - val_acc: 0.0237\n",
      "Epoch 102/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6839 - acc: 0.7977 - val_loss: 9.3258 - val_acc: 0.0202\n",
      "Epoch 103/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6666 - acc: 0.7997 - val_loss: 9.4182 - val_acc: 0.0247\n",
      "Epoch 104/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6554 - acc: 0.7997 - val_loss: 9.5333 - val_acc: 0.0227\n",
      "Epoch 105/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6585 - acc: 0.8034 - val_loss: 9.4924 - val_acc: 0.0247\n",
      "Epoch 106/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6469 - acc: 0.8057 - val_loss: 9.4920 - val_acc: 0.0202\n",
      "Epoch 107/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6529 - acc: 0.8014 - val_loss: 9.6279 - val_acc: 0.0237\n",
      "Epoch 108/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6386 - acc: 0.8042 - val_loss: 9.5704 - val_acc: 0.0288\n",
      "Epoch 109/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.6356 - acc: 0.8019 - val_loss: 9.6913 - val_acc: 0.0262\n",
      "Epoch 110/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.6359 - acc: 0.8019 - val_loss: 9.8043 - val_acc: 0.0252\n",
      "Epoch 111/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6336 - acc: 0.8000 - val_loss: 9.7152 - val_acc: 0.0212\n",
      "Epoch 112/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6212 - acc: 0.8079 - val_loss: 9.7509 - val_acc: 0.0207\n",
      "Epoch 113/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6257 - acc: 0.8009 - val_loss: 9.7918 - val_acc: 0.0212\n",
      "Epoch 114/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6292 - acc: 0.8019 - val_loss: 9.8346 - val_acc: 0.0247\n",
      "Epoch 115/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6446 - acc: 0.7995 - val_loss: 9.8726 - val_acc: 0.0237\n",
      "Epoch 116/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6576 - acc: 0.7955 - val_loss: 9.8724 - val_acc: 0.0197\n",
      "Epoch 117/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6301 - acc: 0.8042 - val_loss: 9.9514 - val_acc: 0.0227\n",
      "Epoch 118/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6379 - acc: 0.7982 - val_loss: 9.9872 - val_acc: 0.0232\n",
      "Epoch 119/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6494 - acc: 0.7965 - val_loss: 10.0295 - val_acc: 0.0232\n",
      "Epoch 120/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6272 - acc: 0.8004 - val_loss: 9.9786 - val_acc: 0.0217\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6225 - acc: 0.8022 - val_loss: 9.8836 - val_acc: 0.0252\n",
      "Epoch 122/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6224 - acc: 0.8044 - val_loss: 10.1127 - val_acc: 0.0212\n",
      "Epoch 123/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6466 - acc: 0.7972 - val_loss: 10.0652 - val_acc: 0.0237\n",
      "Epoch 124/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6377 - acc: 0.7970 - val_loss: 10.1400 - val_acc: 0.0172\n",
      "Epoch 125/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6155 - acc: 0.8007 - val_loss: 10.2128 - val_acc: 0.0207\n",
      "Epoch 126/200\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.6038 - acc: 0.8049 - val_loss: 10.1796 - val_acc: 0.0242\n",
      "Epoch 127/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6052 - acc: 0.8042 - val_loss: 10.1742 - val_acc: 0.0212\n",
      "Epoch 128/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6013 - acc: 0.8039 - val_loss: 10.1926 - val_acc: 0.0166\n",
      "Epoch 129/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6078 - acc: 0.8049 - val_loss: 10.2491 - val_acc: 0.0207\n",
      "Epoch 130/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6080 - acc: 0.8014 - val_loss: 10.3298 - val_acc: 0.0192\n",
      "Epoch 131/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6094 - acc: 0.8019 - val_loss: 10.2857 - val_acc: 0.0212\n",
      "Epoch 132/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6018 - acc: 0.8032 - val_loss: 10.3344 - val_acc: 0.0187\n",
      "Epoch 133/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5973 - acc: 0.8019 - val_loss: 10.3220 - val_acc: 0.0217\n",
      "Epoch 134/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5943 - acc: 0.8074 - val_loss: 10.4256 - val_acc: 0.0227\n",
      "Epoch 135/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6019 - acc: 0.7997 - val_loss: 10.3787 - val_acc: 0.0212\n",
      "Epoch 136/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5989 - acc: 0.8034 - val_loss: 10.3728 - val_acc: 0.0187\n",
      "Epoch 137/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6369 - acc: 0.7932 - val_loss: 10.3803 - val_acc: 0.0242\n",
      "Epoch 138/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6345 - acc: 0.7990 - val_loss: 10.4895 - val_acc: 0.0227\n",
      "Epoch 139/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6145 - acc: 0.8007 - val_loss: 10.3636 - val_acc: 0.0247\n",
      "Epoch 140/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6022 - acc: 0.8012 - val_loss: 10.4270 - val_acc: 0.0202\n",
      "Epoch 141/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5904 - acc: 0.8042 - val_loss: 10.4503 - val_acc: 0.0192\n",
      "Epoch 142/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5891 - acc: 0.8022 - val_loss: 10.4989 - val_acc: 0.0222\n",
      "Epoch 143/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5858 - acc: 0.8022 - val_loss: 10.3745 - val_acc: 0.0202\n",
      "Epoch 144/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5875 - acc: 0.8044 - val_loss: 10.4709 - val_acc: 0.0207\n",
      "Epoch 145/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5907 - acc: 0.8017 - val_loss: 10.5807 - val_acc: 0.0212\n",
      "Epoch 146/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5849 - acc: 0.8037 - val_loss: 10.6077 - val_acc: 0.0222\n",
      "Epoch 147/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5887 - acc: 0.8014 - val_loss: 10.6420 - val_acc: 0.0192\n",
      "Epoch 148/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5865 - acc: 0.8034 - val_loss: 10.6514 - val_acc: 0.0192\n",
      "Epoch 149/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5782 - acc: 0.8057 - val_loss: 10.7895 - val_acc: 0.0222\n",
      "Epoch 150/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5784 - acc: 0.8037 - val_loss: 10.8314 - val_acc: 0.0172\n",
      "Epoch 151/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5783 - acc: 0.8054 - val_loss: 10.7486 - val_acc: 0.0177\n",
      "Epoch 152/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5794 - acc: 0.8047 - val_loss: 10.6569 - val_acc: 0.0232\n",
      "Epoch 153/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5824 - acc: 0.8037 - val_loss: 10.7807 - val_acc: 0.0217\n",
      "Epoch 154/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5883 - acc: 0.8024 - val_loss: 10.6743 - val_acc: 0.0192\n",
      "Epoch 155/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5905 - acc: 0.8017 - val_loss: 10.7888 - val_acc: 0.0166\n",
      "Epoch 156/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5850 - acc: 0.8022 - val_loss: 10.7103 - val_acc: 0.0187\n",
      "Epoch 157/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6009 - acc: 0.8012 - val_loss: 10.7662 - val_acc: 0.0207\n",
      "Epoch 158/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6067 - acc: 0.8019 - val_loss: 10.8017 - val_acc: 0.0197\n",
      "Epoch 159/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6259 - acc: 0.7967 - val_loss: 10.9425 - val_acc: 0.0202\n",
      "Epoch 160/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.8312 - acc: 0.7416 - val_loss: 10.6393 - val_acc: 0.0227\n",
      "Epoch 161/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.7212 - acc: 0.7744 - val_loss: 10.5921 - val_acc: 0.0182\n",
      "Epoch 162/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6262 - acc: 0.7990 - val_loss: 10.7382 - val_acc: 0.0247\n",
      "Epoch 163/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5926 - acc: 0.8019 - val_loss: 10.7238 - val_acc: 0.0202\n",
      "Epoch 164/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5721 - acc: 0.8054 - val_loss: 10.7896 - val_acc: 0.0222\n",
      "Epoch 165/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5731 - acc: 0.8079 - val_loss: 10.7505 - val_acc: 0.0207\n",
      "Epoch 166/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5712 - acc: 0.8007 - val_loss: 10.7192 - val_acc: 0.0212\n",
      "Epoch 167/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5694 - acc: 0.8044 - val_loss: 10.7879 - val_acc: 0.0212\n",
      "Epoch 168/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5681 - acc: 0.8037 - val_loss: 10.8273 - val_acc: 0.0222\n",
      "Epoch 169/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5676 - acc: 0.8054 - val_loss: 10.7765 - val_acc: 0.0227\n",
      "Epoch 170/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5680 - acc: 0.8007 - val_loss: 10.9097 - val_acc: 0.0187\n",
      "Epoch 171/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5652 - acc: 0.8047 - val_loss: 10.8881 - val_acc: 0.0207\n",
      "Epoch 172/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5655 - acc: 0.8039 - val_loss: 10.8632 - val_acc: 0.0187\n",
      "Epoch 173/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5686 - acc: 0.8009 - val_loss: 11.0468 - val_acc: 0.0177\n",
      "Epoch 174/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5643 - acc: 0.8054 - val_loss: 10.9018 - val_acc: 0.0217\n",
      "Epoch 175/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5644 - acc: 0.8044 - val_loss: 10.9150 - val_acc: 0.0192\n",
      "Epoch 176/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5698 - acc: 0.8029 - val_loss: 10.9050 - val_acc: 0.0207\n",
      "Epoch 177/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5679 - acc: 0.8069 - val_loss: 10.9964 - val_acc: 0.0207\n",
      "Epoch 178/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.5640 - acc: 0.8047 - val_loss: 11.1096 - val_acc: 0.0222\n",
      "Epoch 179/200\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.5692 - acc: 0.8037 - val_loss: 10.9744 - val_acc: 0.0192\n",
      "Epoch 180/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5676 - acc: 0.8059 - val_loss: 10.9361 - val_acc: 0.0222\n",
      "Epoch 181/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5695 - acc: 0.8027 - val_loss: 11.0261 - val_acc: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5710 - acc: 0.8022 - val_loss: 11.0344 - val_acc: 0.0232\n",
      "Epoch 183/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.5671 - acc: 0.8064 - val_loss: 11.0845 - val_acc: 0.0182\n",
      "Epoch 184/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5725 - acc: 0.8029 - val_loss: 11.0347 - val_acc: 0.0202\n",
      "Epoch 185/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5739 - acc: 0.8059 - val_loss: 11.1054 - val_acc: 0.0207\n",
      "Epoch 186/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.5739 - acc: 0.8027 - val_loss: 11.0401 - val_acc: 0.0192\n",
      "Epoch 187/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.5721 - acc: 0.8039 - val_loss: 10.9535 - val_acc: 0.0212\n",
      "Epoch 188/200\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.5712 - acc: 0.8047 - val_loss: 11.1239 - val_acc: 0.0192\n",
      "Epoch 189/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.5666 - acc: 0.8042 - val_loss: 11.1073 - val_acc: 0.0232\n",
      "Epoch 190/200\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.5871 - acc: 0.7967 - val_loss: 11.1305 - val_acc: 0.0227\n",
      "Epoch 191/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6219 - acc: 0.7947 - val_loss: 11.0620 - val_acc: 0.0212\n",
      "Epoch 192/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6130 - acc: 0.7910 - val_loss: 10.9808 - val_acc: 0.0212\n",
      "Epoch 193/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5950 - acc: 0.7997 - val_loss: 11.1616 - val_acc: 0.0212\n",
      "Epoch 194/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5887 - acc: 0.8000 - val_loss: 11.0428 - val_acc: 0.0202\n",
      "Epoch 195/200\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 0.6098 - acc: 0.7970 - val_loss: 11.1510 - val_acc: 0.0207\n",
      "Epoch 196/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.6122 - acc: 0.7980 - val_loss: 11.0688 - val_acc: 0.0187\n",
      "Epoch 197/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5925 - acc: 0.8029 - val_loss: 11.1886 - val_acc: 0.0202\n",
      "Epoch 198/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5833 - acc: 0.8002 - val_loss: 11.1720 - val_acc: 0.0207\n",
      "Epoch 199/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5734 - acc: 0.8014 - val_loss: 11.2005 - val_acc: 0.0197\n",
      "Epoch 200/200\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.5639 - acc: 0.8042 - val_loss: 11.2186 - val_acc: 0.0177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27012b149e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=64, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a580bdf",
   "metadata": {},
   "source": [
    "### function returning a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514f6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def seq_generate(model, input_num, verbose=False): \n",
    "    sequence = [input_num]\n",
    "\n",
    "    while len(sequence) < 7:\n",
    "        encoded = pad_sequences([sequence], maxlen=7, padding='pre')\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        \n",
    "        mask = np.zeros(result.size, dtype=bool)\n",
    "        mask[sequence] = True\n",
    "        result = np.ma.array(result, mask=mask)\n",
    "        result = np.argmax(result)\n",
    "\n",
    "        sequence.append(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"sequence:\", sequence)\n",
    "\n",
    "    return [sorted(sequence[:-1]), sequence[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70f70e",
   "metadata": {},
   "source": [
    "테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d164af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0314834e-17 8.9763565e-04 3.1238937e-07 4.7520551e-08 1.3271838e-05\n",
      "  7.9703137e-02 2.2938398e-01 1.2309606e-03 1.2171864e-01 9.8727259e-04\n",
      "  2.7534894e-05 5.7089310e-02 5.0864004e-02 8.9254837e-07 3.9849801e-05\n",
      "  9.2154165e-04 5.5561084e-02 5.2318823e-02 4.5428376e-07 8.0502074e-04\n",
      "  5.8052409e-04 7.8816875e-04 8.4111176e-02 4.8434456e-05 4.7312543e-02\n",
      "  1.4438300e-03 6.1117564e-05 3.3328225e-04 5.8724955e-02 3.4168109e-02\n",
      "  1.8935837e-02 5.4489370e-03 3.2386813e-02 6.5905544e-05 2.8633702e-05\n",
      "  6.1230071e-02 1.3459387e-05 4.4922122e-05 2.3244693e-05 4.1275352e-04\n",
      "  2.1671376e-05 2.4509643e-07 3.5191953e-04 4.8888690e-04 1.3760059e-03\n",
      "  3.4814140e-05]]\n",
      "6\n",
      "sequence: [2, 6]\n",
      "sequence: [2, 6, 13]\n",
      "sequence: [2, 6, 13, 27]\n",
      "sequence: [2, 6, 13, 27, 43]\n",
      "sequence: [2, 6, 13, 27, 43, 17]\n",
      "sequence: [2, 6, 13, 27, 43, 17, 23]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 6, 13, 17, 27, 43], 23]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = 2\n",
    "seq = [[test_num]]\n",
    "encoded = pad_sequences(seq, maxlen=7, padding='pre')\n",
    "result = model.predict(encoded, verbose=0)\n",
    "\n",
    "print(result)\n",
    "print(np.argmax(result))\n",
    "\n",
    "seq_generate(model, test_num, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429329e",
   "metadata": {},
   "source": [
    "### performance result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2bb11",
   "metadata": {},
   "source": [
    "Print the first number in order of frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e11613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    35\n",
       "25    31\n",
       "26    31\n",
       "23    29\n",
       "4     28\n",
       "45    28\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_num = df['1'].value_counts()[:6]\n",
    "first_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47cd235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37: [[10, 18, 20, 31, 37, 42], 27]\n",
      "25: [[6, 15, 19, 25, 33, 38], 26]\n",
      "26: [[5, 20, 26, 27, 35, 45], 23]\n",
      "23: [[3, 4, 22, 23, 36, 41], 9]\n",
      " 4: [[3, 4, 16, 37, 38, 40], 30]\n",
      "45: [[1, 13, 20, 26, 29, 45], 39]\n"
     ]
    }
   ],
   "source": [
    "for num, _ in first_num.iteritems():\n",
    "    print(f\"{num:2}:\", seq_generate(model, num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b141395",
   "metadata": {},
   "source": [
    "모든 숫자에 대해 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21196cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: [[1, 3, 12, 13, 24, 44], 31]\n",
      " 2: [[2, 6, 13, 17, 27, 43], 23]\n",
      " 3: [[3, 8, 21, 22, 34, 41], 12]\n",
      " 4: [[3, 4, 16, 37, 38, 40], 30]\n",
      " 5: [[4, 5, 9, 15, 26, 27], 42]\n",
      " 6: [[2, 4, 6, 10, 11, 37], 28]\n",
      " 7: [[1, 2, 7, 15, 23, 34], 17]\n",
      " 8: [[8, 10, 14, 31, 34, 36], 12]\n",
      " 9: [[6, 9, 12, 14, 26, 37], 31]\n",
      "10: [[5, 10, 13, 21, 28, 35], 9]\n",
      "11: [[10, 11, 18, 22, 28, 39], 30]\n",
      "12: [[1, 10, 12, 18, 24, 35], 31]\n",
      "13: [[6, 13, 25, 28, 38, 45], 39]\n",
      "14: [[8, 14, 18, 30, 31, 44], 15]\n",
      "15: [[6, 10, 11, 15, 19, 34], 25]\n",
      "16: [[16, 17, 23, 24, 29, 44], 3]\n",
      "17: [[4, 5, 6, 8, 17, 39], 25]\n",
      "18: [[13, 15, 17, 18, 25, 33], 37]\n",
      "19: [[6, 11, 16, 19, 20, 28], 12]\n",
      "20: [[3, 20, 22, 33, 40, 44], 8]\n",
      "21: [[11, 15, 21, 22, 26, 35], 37]\n",
      "22: [[9, 14, 20, 22, 33, 34], 13]\n",
      "23: [[3, 4, 22, 23, 36, 41], 9]\n",
      "24: [[8, 15, 24, 26, 39, 41], 22]\n",
      "25: [[6, 15, 19, 25, 33, 38], 26]\n",
      "26: [[5, 20, 26, 27, 35, 45], 23]\n",
      "27: [[2, 13, 21, 25, 27, 42], 38]\n",
      "28: [[5, 18, 19, 28, 31, 32], 12]\n",
      "29: [[7, 8, 11, 29, 32, 34], 20]\n",
      "30: [[10, 12, 13, 26, 29, 30], 7]\n",
      "31: [[5, 10, 16, 17, 31, 32], 21]\n",
      "32: [[3, 10, 11, 15, 25, 32], 2]\n",
      "33: [[7, 14, 19, 22, 32, 33], 15]\n",
      "34: [[9, 17, 19, 24, 30, 34], 13]\n",
      "35: [[7, 10, 13, 35, 36, 44], 12]\n",
      "36: [[22, 26, 27, 35, 36, 39], 20]\n",
      "37: [[10, 18, 20, 31, 37, 42], 27]\n",
      "38: [[21, 25, 38, 39, 41, 45], 30]\n",
      "39: [[6, 9, 10, 11, 39, 41], 27]\n",
      "40: [[15, 25, 28, 38, 40, 43], 31]\n",
      "41: [[2, 4, 8, 32, 40, 41], 29]\n",
      "42: [[1, 25, 34, 36, 41, 42], 33]\n",
      "43: [[8, 15, 22, 30, 37, 43], 40]\n",
      "44: [[10, 13, 31, 38, 43, 44], 17]\n",
      "45: [[1, 13, 20, 26, 29, 45], 39]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 46):\n",
    "    print(f\"{i:2}:\", seq_generate(model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b871b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
