{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71d4241",
   "metadata": {},
   "source": [
    "# 로또 번호 예측 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6652049",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812590bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"lotto.csv\", index_col=0) # 순서 미포함\n",
    "df = pd.read_csv(\"lotto_ord.csv\", index_col=0) # 순서 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6d42e",
   "metadata": {},
   "source": [
    "최근 n개의 데이터만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f5fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66860b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df[-300:-200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9424f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>17</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>17</td>\n",
       "      <td>44</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1   2   3   4   5   6   B\n",
       "801   36  16  24  42  43  27   1\n",
       "802   11  17  23  10  41   9  26\n",
       "803   25   8   4  13  42  29   1\n",
       "804   35  25  12   0   9  31   8\n",
       "805   17  31  11   2  30  12  41\n",
       "...   ..  ..  ..  ..  ..  ..  ..\n",
       "996    5  10  23  14  31  38  27\n",
       "997   15   6   3  43  23  13  19\n",
       "998   17  44  12  19  16  41  40\n",
       "999    8   0  27   2  17  13  33\n",
       "1000  18   1   7  21  41  31  38\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab7d88",
   "metadata": {},
   "source": [
    "1\\~45의 번호를 0\\~44로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975e7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395c17e",
   "metadata": {},
   "source": [
    "당첨번호 리스트를 가공하여 sequences 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8ffa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 1200\n"
     ]
    }
   ],
   "source": [
    "train_sequences = list()\n",
    "for _, seq in train.iterrows():\n",
    "    for i in range(1, len(seq)):\n",
    "        sequence = list(seq)[:i+1]\n",
    "        train_sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(train_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45432608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36, 16],\n",
       " [36, 16, 24],\n",
       " [36, 16, 24, 42],\n",
       " [36, 16, 24, 42, 43],\n",
       " [36, 16, 24, 42, 43, 27]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41021274",
   "metadata": {},
   "source": [
    "검증 데이터에도 동일하게 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348958e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증에 사용할 샘플의 개수: 1200\n"
     ]
    }
   ],
   "source": [
    "valid_sequences = list()\n",
    "for _, seq in valid.iterrows():\n",
    "    for i in range(1, len(seq)):\n",
    "        sequence = list(seq)[:i+1]\n",
    "        valid_sequences.append(sequence)\n",
    "        \n",
    "print('검증에 사용할 샘플의 개수: %d' % len(valid_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4557a79d",
   "metadata": {},
   "source": [
    "잘린 sequences의 길이를 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=7, padding='pre')\n",
    "valid_sequences = pad_sequences(valid_sequences, maxlen=7, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e156cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1200, 6)\n",
      "y_train.shape: (1200,)\n",
      "X_valid.shape: (600, 6)\n",
      "y_valid.shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_sequences = np.array(train_sequences)\n",
    "valid_sequences = np.array(valid_sequences)\n",
    "X_train = train_sequences[:,:-1]\n",
    "y_train = train_sequences[:,-1]\n",
    "X_valid = valid_sequences[:,:-1]\n",
    "y_valid = valid_sequences[:,-1]\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_valid.shape:\", X_valid.shape)\n",
    "print(\"y_valid.shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab662d",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "134bb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(45, 10))\n",
    "model.add(LSTM(64, input_shape=(6, 1), return_sequences=False))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(45, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61fe59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\seungwon\\anaconda3\\envs\\scratch\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5075: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/200\n",
      "38/38 [==============================] - 10s 80ms/step - loss: 3.8075 - acc: 0.0150 - val_loss: nan - val_acc: 0.0300\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.8043 - acc: 0.0242 - val_loss: nan - val_acc: 0.0383\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.8004 - acc: 0.0267 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.7959 - acc: 0.0308 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 3.7915 - acc: 0.0317 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.7838 - acc: 0.0417 - val_loss: nan - val_acc: 0.0333\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.7741 - acc: 0.0450 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.7605 - acc: 0.0383 - val_loss: nan - val_acc: 0.0150\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 3.7490 - acc: 0.0450 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.7349 - acc: 0.0400 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.7142 - acc: 0.0442 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.6939 - acc: 0.0492 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 3.6783 - acc: 0.0525 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.6563 - acc: 0.0508 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.6352 - acc: 0.0683 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.6118 - acc: 0.0750 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.5953 - acc: 0.0708 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 3.5662 - acc: 0.0742 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.5457 - acc: 0.0792 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 3.5231 - acc: 0.0908 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 3.4971 - acc: 0.0842 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 3.4778 - acc: 0.0933 - val_loss: nan - val_acc: 0.0283\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.4515 - acc: 0.0933 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 3.4176 - acc: 0.1000 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.4035 - acc: 0.1083 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.3641 - acc: 0.1075 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.3405 - acc: 0.1125 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 3.3177 - acc: 0.1300 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.2853 - acc: 0.1250 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.2566 - acc: 0.1408 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.2289 - acc: 0.1350 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.1970 - acc: 0.1342 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 3s 68ms/step - loss: 3.1744 - acc: 0.1425 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 3.1368 - acc: 0.1617 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.1065 - acc: 0.1600 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.0724 - acc: 0.1750 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 3.0431 - acc: 0.1742 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 3.0203 - acc: 0.1808 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.9712 - acc: 0.1892 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.9348 - acc: 0.1992 - val_loss: nan - val_acc: 0.0150\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.9039 - acc: 0.2100 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.8723 - acc: 0.2233 - val_loss: nan - val_acc: 0.0300\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.8420 - acc: 0.2325 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.8104 - acc: 0.2367 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.7715 - acc: 0.2492 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.7361 - acc: 0.2583 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.7117 - acc: 0.2758 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.6633 - acc: 0.2842 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.6258 - acc: 0.3017 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.5907 - acc: 0.3067 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.5603 - acc: 0.3183 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 2.5242 - acc: 0.3225 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 2.5019 - acc: 0.3183 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.4548 - acc: 0.3392 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.4362 - acc: 0.3583 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.3943 - acc: 0.3575 - val_loss: nan - val_acc: 0.0133\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.3485 - acc: 0.3842 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.3247 - acc: 0.3825 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.2903 - acc: 0.3958 - val_loss: nan - val_acc: 0.0283\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.2514 - acc: 0.4133 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 2.2195 - acc: 0.4117 - val_loss: nan - val_acc: 0.0283\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.1897 - acc: 0.4325 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.1540 - acc: 0.4375 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.1193 - acc: 0.4375 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.1098 - acc: 0.4417 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 2.0519 - acc: 0.4567 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.0211 - acc: 0.4633 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.9923 - acc: 0.4792 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.9722 - acc: 0.4867 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 1.9329 - acc: 0.4875 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.9003 - acc: 0.5000 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.8751 - acc: 0.5192 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.8449 - acc: 0.5133 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 3s 68ms/step - loss: 1.8073 - acc: 0.5242 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.7794 - acc: 0.5375 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.7569 - acc: 0.5425 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.7229 - acc: 0.5517 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6914 - acc: 0.5667 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6664 - acc: 0.5650 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6386 - acc: 0.5767 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6098 - acc: 0.5742 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.5946 - acc: 0.5867 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.5550 - acc: 0.5942 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.5343 - acc: 0.5975 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.5145 - acc: 0.6058 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.4923 - acc: 0.6083 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.4629 - acc: 0.6242 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.4385 - acc: 0.6292 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.4227 - acc: 0.6283 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.3993 - acc: 0.6325 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.3663 - acc: 0.6483 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.3460 - acc: 0.6475 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.3125 - acc: 0.6600 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.3033 - acc: 0.6608 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2782 - acc: 0.6683 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2628 - acc: 0.6717 - val_loss: nan - val_acc: 0.0283\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.2335 - acc: 0.6875 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.2103 - acc: 0.6992 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1833 - acc: 0.7008 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1714 - acc: 0.7050 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 101/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1449 - acc: 0.7050 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1194 - acc: 0.7133 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1091 - acc: 0.7183 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0973 - acc: 0.7250 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0711 - acc: 0.7267 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0478 - acc: 0.7350 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0321 - acc: 0.7408 - val_loss: nan - val_acc: 0.0150\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0147 - acc: 0.7483 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9915 - acc: 0.7517 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9861 - acc: 0.7550 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9624 - acc: 0.7558 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9364 - acc: 0.7617 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9217 - acc: 0.7642 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9061 - acc: 0.7742 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8908 - acc: 0.7883 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8917 - acc: 0.7808 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8621 - acc: 0.7883 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8513 - acc: 0.7875 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8286 - acc: 0.7950 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8197 - acc: 0.7983 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8013 - acc: 0.8017 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7944 - acc: 0.8050 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7851 - acc: 0.8050 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7713 - acc: 0.8167 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7721 - acc: 0.8067 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7358 - acc: 0.8200 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7270 - acc: 0.8125 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7259 - acc: 0.8133 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.7061 - acc: 0.8200 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6982 - acc: 0.8283 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6865 - acc: 0.8292 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6793 - acc: 0.8217 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6818 - acc: 0.8192 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6528 - acc: 0.8267 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6424 - acc: 0.8350 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6332 - acc: 0.8392 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6297 - acc: 0.8392 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6151 - acc: 0.8317 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6093 - acc: 0.8342 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.6113 - acc: 0.8350 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5939 - acc: 0.8408 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5815 - acc: 0.8392 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5806 - acc: 0.8400 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5712 - acc: 0.8425 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5589 - acc: 0.8433 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5581 - acc: 0.8442 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5449 - acc: 0.8425 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5375 - acc: 0.8425 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5410 - acc: 0.8442 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5206 - acc: 0.8492 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5182 - acc: 0.8500 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5136 - acc: 0.8492 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5169 - acc: 0.8442 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.5044 - acc: 0.8450 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5029 - acc: 0.8442 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4866 - acc: 0.8500 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4890 - acc: 0.8533 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4778 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4830 - acc: 0.8500 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4802 - acc: 0.8475 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4713 - acc: 0.8533 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4669 - acc: 0.8475 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4695 - acc: 0.8533 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4525 - acc: 0.8517 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4592 - acc: 0.8483 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4512 - acc: 0.8567 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4432 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4432 - acc: 0.8575 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4394 - acc: 0.8483 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4351 - acc: 0.8583 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4350 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4328 - acc: 0.8467 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4252 - acc: 0.8525 - val_loss: nan - val_acc: 0.0150\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4285 - acc: 0.8517 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4210 - acc: 0.8517 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4195 - acc: 0.8483 - val_loss: nan - val_acc: 0.0150\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4186 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4217 - acc: 0.8500 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4200 - acc: 0.8458 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4138 - acc: 0.8467 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4045 - acc: 0.8483 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4064 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3994 - acc: 0.8567 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.4050 - acc: 0.8508 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3980 - acc: 0.8483 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3902 - acc: 0.8508 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3924 - acc: 0.8575 - val_loss: nan - val_acc: 0.0167\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3971 - acc: 0.8492 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3941 - acc: 0.8458 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3870 - acc: 0.8550 - val_loss: nan - val_acc: 0.0267\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3918 - acc: 0.8492 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3897 - acc: 0.8467 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3909 - acc: 0.8475 - val_loss: nan - val_acc: 0.0200\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3800 - acc: 0.8467 - val_loss: nan - val_acc: 0.0217\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3814 - acc: 0.8525 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3852 - acc: 0.8475 - val_loss: nan - val_acc: 0.0250\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3805 - acc: 0.8525 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3785 - acc: 0.8558 - val_loss: nan - val_acc: 0.0183\n",
      "Epoch 199/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3735 - acc: 0.8525 - val_loss: nan - val_acc: 0.0233\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3811 - acc: 0.8533 - val_loss: nan - val_acc: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc810e8400>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a580bdf",
   "metadata": {},
   "source": [
    "### 번호 리스트를 반환하는  함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514f6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def seq_generate(model, input_num, verbose=False): \n",
    "    sequence = [input_num-1]\n",
    "\n",
    "    while len(sequence) < 7:\n",
    "        encoded = pad_sequences([sequence], maxlen=7, padding='pre')\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        \n",
    "        mask = np.zeros(result.size, dtype=bool)\n",
    "        mask[sequence] = True\n",
    "        result = np.ma.array(result, mask=mask)\n",
    "        result = np.argmax(result)\n",
    "\n",
    "        sequence.append(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"sequence:\", np.array(sequence)+1)\n",
    "\n",
    "    return sorted(np.array(sequence)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70f70e",
   "metadata": {},
   "source": [
    "테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7d164af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.2144099e-04 1.7221245e-03 2.0790415e-02 4.0945569e-03 7.2814822e-05\n",
      "  8.6311527e-02 1.7217269e-05 3.1626038e-02 4.4568129e-05 1.2823209e-04\n",
      "  2.0120796e-03 6.1575707e-02 3.2064196e-04 1.5749189e-03 4.8646745e-03\n",
      "  5.7824992e-02 2.7600804e-02 3.4341536e-02 7.4056420e-04 2.8835844e-02\n",
      "  3.1393385e-03 5.3425538e-03 6.2311320e-03 4.4577294e-03 9.8606710e-05\n",
      "  4.2753897e-04 5.8926247e-02 3.5226934e-02 4.7481764e-02 1.7538142e-01\n",
      "  2.1246040e-02 5.2361344e-03 8.1400282e-07 5.8825933e-03 9.5033705e-02\n",
      "  1.3609278e-02 6.9210009e-04 2.9512795e-03 2.2023295e-03 4.1593242e-02\n",
      "  3.7730773e-04 5.6720413e-03 6.6656433e-04 1.0303250e-01 7.0117581e-05]]\n",
      "30\n",
      "sequence: [ 2 30]\n",
      "sequence: [ 2 30 28]\n",
      "sequence: [ 2 30 28 45]\n",
      "sequence: [ 2 30 28 45 43]\n",
      "sequence: [ 2 30 28 45 43 38]\n",
      "sequence: [ 2 30 28 45 43 38 40]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 28, 30, 38, 40, 43, 45]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_num = 2\n",
    "seq = [[test_num]]\n",
    "encoded = pad_sequences(np.array(seq)-1, maxlen=7, padding='pre')\n",
    "result = model.predict(encoded, verbose=0)\n",
    "\n",
    "print(result)\n",
    "print(np.argmax(result)+1)\n",
    "\n",
    "seq_generate(model, test_num, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429329e",
   "metadata": {},
   "source": [
    "### 수행 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2bb11",
   "metadata": {},
   "source": [
    "첫번째로 나오는 번호 빈도순으로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4e11613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37    35\n",
       "25    31\n",
       "26    31\n",
       "23    29\n",
       "4     28\n",
       "45    28\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_num = df['1'].value_counts()[:6]\n",
    "first_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cd235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37: [3, 8, 17, 26, 37, 38, 39]\n",
      "25: [9, 10, 18, 23, 25, 34, 35]\n",
      "26: [2, 7, 8, 13, 23, 26, 44]\n",
      "23: [14, 17, 18, 23, 24, 26, 34]\n",
      " 4: [1, 4, 8, 28, 36, 42, 45]\n",
      "45: [8, 11, 19, 21, 25, 36, 45]\n"
     ]
    }
   ],
   "source": [
    "for num, _ in first_num.iteritems():\n",
    "    print(f\"{num:2}:\", seq_generate(model, num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b141395",
   "metadata": {},
   "source": [
    "모든 숫자에 대해 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21196cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: [1, 2, 8, 14, 23, 27, 44]\n",
      " 2: [2, 28, 30, 38, 40, 43, 45]\n",
      " 3: [3, 6, 11, 13, 27, 31, 34]\n",
      " 4: [1, 4, 8, 28, 36, 42, 45]\n",
      " 5: [5, 13, 21, 23, 27, 39, 43]\n",
      " 6: [1, 6, 11, 17, 18, 20, 37]\n",
      " 7: [7, 15, 20, 25, 29, 30, 34]\n",
      " 8: [8, 10, 18, 22, 35, 42, 43]\n",
      " 9: [7, 9, 12, 15, 19, 23, 24]\n",
      "10: [1, 3, 10, 11, 12, 35, 38]\n",
      "11: [11, 20, 22, 25, 31, 40, 41]\n",
      "12: [5, 7, 12, 13, 31, 38, 43]\n",
      "13: [13, 15, 16, 36, 38, 39, 45]\n",
      "14: [2, 8, 13, 14, 23, 27, 44]\n",
      "15: [13, 15, 18, 25, 31, 33, 43]\n",
      "16: [2, 8, 13, 16, 19, 39, 44]\n",
      "17: [7, 11, 13, 17, 18, 29, 43]\n",
      "18: [5, 14, 18, 22, 31, 43, 44]\n",
      "19: [4, 8, 19, 23, 28, 36, 39]\n",
      "20: [1, 8, 19, 20, 21, 37, 39]\n",
      "21: [7, 11, 21, 27, 29, 43, 44]\n",
      "22: [4, 14, 22, 23, 27, 28, 45]\n",
      "23: [14, 17, 18, 23, 24, 26, 34]\n",
      "24: [12, 13, 16, 24, 29, 43, 44]\n",
      "25: [9, 10, 18, 23, 25, 34, 35]\n",
      "26: [2, 7, 8, 13, 23, 26, 44]\n",
      "27: [3, 23, 24, 27, 34, 41, 43]\n",
      "28: [1, 9, 11, 14, 28, 31, 44]\n",
      "29: [4, 7, 13, 18, 29, 31, 39]\n",
      "30: [14, 27, 30, 31, 35, 40, 43]\n",
      "31: [4, 8, 10, 16, 31, 35, 36]\n",
      "32: [4, 9, 18, 20, 26, 27, 32]\n",
      "33: [7, 11, 16, 21, 24, 33, 34]\n",
      "34: [1, 9, 18, 19, 29, 30, 34]\n",
      "35: [4, 10, 14, 15, 20, 24, 35]\n",
      "36: [3, 10, 12, 14, 26, 35, 36]\n",
      "37: [3, 8, 17, 26, 37, 38, 39]\n",
      "38: [8, 15, 21, 32, 35, 38, 42]\n",
      "39: [2, 5, 12, 14, 24, 34, 39]\n",
      "40: [10, 32, 40, 41, 42, 43, 44]\n",
      "41: [12, 14, 18, 22, 24, 33, 41]\n",
      "42: [3, 11, 13, 34, 42, 43, 44]\n",
      "43: [12, 16, 21, 28, 35, 39, 43]\n",
      "44: [11, 21, 27, 29, 37, 38, 44]\n",
      "45: [8, 11, 19, 21, 25, 36, 45]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 46):\n",
    "    print(f\"{i:2}:\", seq_generate(model, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b871b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
